{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import linear_model\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.stats as st\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def LoadTextDifficulties():\n",
    "    df = pd.read_csv(\"./data/reading/t_difficulty_1.csv\",header=None)\n",
    "    difficulties1 = {\n",
    "        x[0].replace(\"Text \",\"\").strip(): x[1] for x in df.values\n",
    "    }\n",
    "    df = pd.read_csv(\"./data/reading/t_difficulty_2.csv\",header=None)\n",
    "    difficulties2 = {\n",
    "        x[0].replace(\"T\",\"\").strip(): x[1] for x in df.values\n",
    "    }\n",
    "    return difficulties1,difficulties2\n",
    "\n",
    "def GetAnswer(user_id,user_name,text_id,question_id):\n",
    "    q = question_id\n",
    "    df = pd.read_csv(\"./data/reading/ParticipantAnswer_N.csv\")\n",
    "    \n",
    "    #r = df[(df[\"User ID\"]==user_id)&(df[\" Text ID\"]==text_id)&(df[\"Group\"].apply(lambda x: x in user_name))][\"Score\"].values\n",
    "    r = df[df.apply(lambda x: (x[\"User initials\"]+\"_\"+x[\"Group\"]==user_name.strip()) and (x[\" Text ID\"]==text_id) ,axis=1)][\"Score\"].values\n",
    "    if((int(q)==0) or (int(q)==4)):\n",
    "        return sum([int(x) for x in r])/len(r)\n",
    "    #assert len(r)==3,print(user_id,text_id,user_name,r)\n",
    "    if (len(r)!=3):\n",
    "        #print(user_id,text_id,user_name,r)\n",
    "        return r[int(q)-1]\n",
    "    return r[int(q)-1]\n",
    "   \n",
    "\n",
    "def GetData(file_name,text_set):\n",
    "    difficulties1,difficulties2 = LoadTextDifficulties()\n",
    "    \n",
    "    attentions = pd.read_csv(file_name)\n",
    "    attentions = attentions[attentions[\"Text ID\"].isin(text_set)]\n",
    "    attentions[\"Difficulty_1\"] = attentions[\"Text ID\"].apply(lambda x: difficulties1[str(int(x))])\n",
    "    attentions[\"Difficulty_2\"] = attentions[\"Text ID\"].apply(lambda x: difficulties2[str(int(x))])\n",
    "    if(\"sentence\" not in file_name.lower()):\n",
    "        #attentions[\" User ID\"] = attentions.apply(lambda x: 6 if (x[\" User Name\"]==\"MG_Control\") else x[\" User ID\"], axis=1)\n",
    "        attentions[\"Answer\"] = attentions.apply(lambda x: GetAnswer(x[\" User ID\"], x[\" User Name\"], x[\"Text ID\"], x[\"Paragraph_Number\"]),axis=1)\n",
    "        \n",
    "    #attentions = attentions[~attentions[\" User Name\"].isin(ignored_users)]\n",
    "#attentions = attentions.sample(frac=1).reset_index(drop=True)\n",
    "    attentions_original=attentions[attentions[\" Time to 1st View (sec)\"]>0].reset_index(drop=True)\n",
    "    attentions_original = attentions_original[attentions_original[\" Time to 1st View (sec)\"]>0]\n",
    "    \n",
    "    if(\"Group\" not in attentions_original.columns):\n",
    "        attentions_original[\"Group\"] = attentions_original[\" User Name\"].apply(lambda x: \"ASD\" if x.endswith(\"ASD\") else \"Control\")\n",
    "        \n",
    "    attentions_original[\"Group_bin\"] = attentions_original[\"Group\"].apply(lambda x: 0 if x==\"ASD\" else 1)\n",
    "    attentions_original[\"Group_bin\"] = attentions_original[\"Group\"].apply(lambda x: 0 if x==\"ASD\" else 1)\n",
    "    \n",
    "    text_id_count  = attentions_original[[\"Text ID\", \" User ID\", \" User Name\"]].drop_duplicates().groupby(\" User Name\", as_index=False)[[\"Text ID\"]].count()\n",
    "    good_text_id_count_users = text_id_count[text_id_count[\"Text ID\"]==len(text_set)][\" User Name\"]\n",
    "    attentions_original = attentions_original[attentions_original[\" User Name\"].isin(good_text_id_count_users)]\n",
    "    user_asd_original = attentions_original[(attentions_original[\"Group\"]=='ASD')][\" User Name\"].unique()\n",
    "    user_control_original=attentions_original[(attentions_original[\"Group\"]=='Control')][\" User Name\"].unique()\n",
    "    if(len(set(user_asd_original).intersection(user_control_original))!=0):\n",
    "        attentions_original[\" User Name\"] = attentions_original.apply(lambda x: x[\" User Name\"]+\"_\"+x[\"Group\"], axis=1)\n",
    "        user_asd_original = attentions_original[attentions_original[\"Group\"]=='ASD'][\" User Name\"].unique()\n",
    "        user_control_original=attentions_original[attentions_original[\"Group\"]=='Control'][\" User Name\"].unique()\n",
    "    print(\"number of asd: {}; control: {}\".format(len(user_asd_original),len(user_control_original)))\n",
    "    return attentions_original,user_asd_original,user_control_original\n",
    "\n",
    "def RunSingleExperiment(attentions,user_asd_original,user_control_original,n_user_test,train_length,n_folds,one_hot_columns,eclf):\n",
    "    \n",
    "    features_one_hots = [x for x in attentions.columns if any(x.startswith(y+\"_\") for y in one_hot_columns)]\n",
    "    results_clf = {\n",
    "        x[0]:[] for x in eclf.estimators\n",
    "    }\n",
    "    results_clf.update({\"ensemble\":[]})\n",
    "    for i in range(0,n_folds):\n",
    "        user_asd_test = np.random.choice(user_asd_original,n_user_test)\n",
    "        user_asd_train = random.sample([x for x in user_asd_original if x not in user_asd_test],train_length)\n",
    "        user_control_test = np.random.choice(user_control_original,n_user_test)\n",
    "        user_control_train = random.sample([x for x in user_control_original if x not in user_control_test],train_length)\n",
    "\n",
    "\n",
    "        attentions_train=attentions[(((attentions[\" User Name\"].isin(user_asd_train)) & (attentions[\"Group\"]==\"ASD\"))\n",
    "                                      |((attentions[\" User Name\"].isin(user_control_train)) & (attentions[\"Group\"]==\"Control\")))]\n",
    "\n",
    "        attentions_test=attentions[(((attentions[\" User Name\"].isin(user_asd_test)) & (attentions[\"Group\"]==\"ASD\"))\n",
    "                                      |((attentions[\" User Name\"].isin(user_control_test)) & (attentions[\"Group\"]==\"Control\")))]\n",
    "\n",
    "\n",
    "        attentions_train_X=attentions_train[features+features_one_hots]\n",
    "        attentions_train_Y=attentions_train[\"Group\"]\n",
    "        attentions_test_X=attentions_test[features+features_one_hots]\n",
    "        attentions_test_Y=attentions_test[\"Group\"]\n",
    "        eclf.fit(attentions_train_X,attentions_train_Y)\n",
    "        attentions_test_Y_n = attentions_test_Y.apply(lambda x: list(eclf.classes_).index(x))\n",
    "        for clf in eclf.named_estimators_:\n",
    "            #clfs[clf].fit(attentions_train_X,attentions_train_Y)\n",
    "            results=eclf.named_estimators_[clf].predict(attentions_test_X)==attentions_test_Y_n\n",
    "            train_outcome=[]\n",
    "            for user in user_control_test:\n",
    "                user_asd_x=attentions[(attentions[\" User Name\"]==user) & (attentions[\"Group\"]==\"Control\")].index\n",
    "                r_x=results[user_asd_x].value_counts()\n",
    "                train_outcome.append(r_x.index[0])\n",
    "\n",
    "            for user in user_asd_test:\n",
    "                user_asd_x=attentions[(attentions[\" User Name\"]==user) & (attentions[\"Group\"]==\"ASD\")].index\n",
    "                r_x=results[user_asd_x].value_counts()\n",
    "                train_outcome.append(r_x.index[0])\n",
    "            correct = sum(train_outcome)\n",
    "            results_clf[clf].append(correct)\n",
    "        results=eclf.predict(attentions_test_X)==attentions_test_Y\n",
    "        train_outcome=[]\n",
    "        for user in user_control_test:\n",
    "            user_asd_x=attentions[(attentions[\" User Name\"]==user) & (attentions[\"Group\"]==\"Control\")].index\n",
    "            r_x=results[user_asd_x].value_counts()\n",
    "            train_outcome.append(r_x.index[0])\n",
    "\n",
    "        for user in user_asd_test:\n",
    "            user_asd_x=attentions[(attentions[\" User Name\"]==user) & (attentions[\"Group\"]==\"ASD\")].index\n",
    "            r_x=results[user_asd_x].value_counts()\n",
    "            train_outcome.append(r_x.index[0])\n",
    "        correct = sum(train_outcome)\n",
    "        results_clf[\"ensemble\"].append(correct)\n",
    "    #print(one_hot_columns,results_clf)\n",
    "\n",
    "    \n",
    "    for m in results_clf:\n",
    "        a = results_clf[m]\n",
    "        a = np.array(a)/n_user_test/2\n",
    "        results_clf[m] = a\n",
    "        print(one_hot_columns,m, np.mean(a), st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a)),sep=\"|\")\n",
    "    return results_clf\n",
    "\n",
    "def RunExperiments(file_name,text_set,n_user_test,n_folds,features,one_hot_columns_all,eclf):\n",
    "    attentions_original,user_asd_original,user_control_original = GetData(file_name,text_set)\n",
    "    grand_results = {\n",
    "    \n",
    "    }\n",
    "    attentions = pd.get_dummies(attentions_original,columns=one_hot_columns_all)\n",
    "    min_length = min(len(user_asd_original),len(user_control_original))\n",
    "    print(\"number of selected users: \", min_length*2)\n",
    "    n_user_test = round(min_length*0.33) if n_user_test == -1 else n_user_test\n",
    "    print(\"number of selected test users: \", n_user_test*2)\n",
    "    train_length = min_length - n_user_test\n",
    "    print(\"number of selected train users: \", train_length*2)\n",
    "    for n_onehot in range(1,len(one_hot_columns_all)+1):\n",
    "        for one_hot_columns in list(itertools.combinations(one_hot_columns_all,n_onehot))+[()]:    \n",
    "            if(one_hot_columns in grand_results):\n",
    "                continue\n",
    "            grand_results[one_hot_columns] = (attentions,\n",
    "                                              user_asd_original,\n",
    "                                              user_control_original,\n",
    "                                              n_user_test,\n",
    "                                              train_length,\n",
    "                                              n_folds,\n",
    "                                              one_hot_columns,\n",
    "                                              eclf)\n",
    "            \n",
    "    return grand_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns_by_AOI = {}\n",
    "one_hot_columns_by_AOI[\"general\"] = [\" AOI Name\", \"Text ID\"]#, \"Paragraph_Number\",\"Answer\",\"Difficulty_1\", \"Flag\"]\n",
    "one_hot_columns_by_AOI[\"Title_paragraphs\"] = one_hot_columns_by_AOI[\"general\"] +  [\"Paragraph_Number\",\"Answer\",\"Difficulty_1\"]\n",
    "one_hot_columns_by_AOI[\"Questions\"] = one_hot_columns_by_AOI[\"general\"] +  [\"Paragraph_Number\",\"Answer\"]\n",
    "one_hot_columns_by_AOI[\"Sentences\"] = one_hot_columns_by_AOI[\"general\"] +  [\"Difficulty_1\"]\n",
    "one_hot_columns_by_AOI[\"Title_paragraphs_Questions_combined\"] = one_hot_columns_by_AOI[\"general\"] +  [\"Paragraph_Number\",\"Answer\",\"Difficulty_1\",\"Flag\"]\n",
    "\n",
    "\n",
    "set_1 = [1,2,3,4,5,6,7,8,9]\n",
    "set_2 = [10,11,12,13,14,15,16,17]\n",
    "set_3 = [18,19,20]\n",
    "\n",
    "features = [' Time to 1st View (sec)', ' Time Viewed (sec)',\n",
    "        ' Fixations (#)', ' Revisits (#)']\n",
    "\n",
    "eclf = sklearn.ensemble.VotingClassifier(estimators=[\n",
    "    ('randomForest', RandomForestClassifier(n_estimators=100, n_jobs=-1)),\n",
    "    ('kNeigh', KNeighborsClassifier()), \n",
    "    ('svc', svm.SVC()), \n",
    "    ('logistic', linear_model.LogisticRegression(max_iter=10000)), \n",
    "    ('logisticCV', linear_model.LogisticRegressionCV(max_iter=10000)), \n",
    "    (\"XGBClassifier\",XGBClassifier(n_jobs=-1,nthreads=-1))],\n",
    "                                         voting='hard')\n",
    "import os\n",
    "\n",
    "input_files_by_AOI_setting = {}\n",
    "input_files_by_AOI_setting[\"Title_paragraphs\"] = \"./data/reading/Title_paragraph.csv\"\n",
    "input_files_by_AOI_setting[\"Questions\"] = \"./data/reading/Questions.csv\"\n",
    "input_files_by_AOI_setting[\"Sentences\"] = \"./data/reading/Sentence_aggregate.csv\"\n",
    "input_files_by_AOI_setting[\"Title_paragraphs_Questions_combined\"] = \"./data/reading/Text_question_combined.csv\"\n",
    "\n",
    "n_folds = 1\n",
    "AOI_setting_results = {}\n",
    "for AOI_setting in input_files_by_AOI_setting:\n",
    "    print(\"current AOI setting:\", AOI_setting)\n",
    "    file_name = input_files_by_AOI_setting[AOI_setting]\n",
    "    text_set_results = {}\n",
    "    for text_set in zip([\"set_1\",\"set_2\",\"set_3\"],[set_1,set_2,set_3]):\n",
    "        \n",
    "        attentions_original,user_asd_original,user_control_original = GetData(file_name,text_set[1])\n",
    "        n_user_test = -1\n",
    "        attentions = pd.get_dummies(attentions_original,columns=one_hot_columns_by_AOI[AOI_setting])\n",
    "        min_length = min(len(user_asd_original),len(user_control_original))\n",
    "        print(\"number of selected users: \", min_length*2)\n",
    "        n_user_test = round(min_length*0.33) if n_user_test == -1 else n_user_test\n",
    "        print(\"number of selected test users: \", n_user_test*2)\n",
    "        train_length = min_length - n_user_test\n",
    "        print(\"number of selected train users: \", train_length*2)\n",
    "        \n",
    "        one_hot_columns_set = [()]\n",
    "        for column in one_hot_columns_by_AOI[AOI_setting]:\n",
    "            one_hot_columns_set = one_hot_columns_set + [x+ (column,) for x in one_hot_columns_set]\n",
    "\n",
    "        #one_hot_columns_set = [('Answer',), (\" AOI Name\", \"Answer\"),(\"Text ID\",\"Answer\"), (\" AOI Name\",\"Text ID\",\"Answer\")]\n",
    "        #one_hot_columns_set = [(),(\" AOI Name\"),(\"Text ID\"),(\" AOI Name\",\"Text ID\")]\n",
    "        \n",
    "        by_columns_results = {}\n",
    "        for one_hot_columns in tqdm(one_hot_columns_set):\n",
    "        #for one_hot_columns in one_hot_columns_set:\n",
    "            by_columns_results[one_hot_columns] = RunSingleExperiment(attentions,user_asd_original,user_control_original,n_user_test,train_length,n_folds,one_hot_columns,eclf)\n",
    "        text_set_results[text_set[0]] = by_columns_results\n",
    "    AOI_setting_results[AOI_setting] = text_set_results\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_df = []\n",
    "\n",
    "for AOI_setting in input_files_by_AOI_setting:\n",
    "    for text_set in [\"set_1\",\"set_2\",\"set_3\"]:\n",
    "        one_hot_columns_set = [()]\n",
    "        for column in one_hot_columns_by_AOI[AOI_setting]:\n",
    "            one_hot_columns_set = one_hot_columns_set + [x+ (column,) for x in one_hot_columns_set]\n",
    "        for one_hot_columns in one_hot_columns_set:\n",
    "            for ml in AOI_setting_results[AOI_setting][text_set][one_hot_columns]:\n",
    "                a = AOI_setting_results[AOI_setting][text_set][one_hot_columns][ml]\n",
    "                for_df.append ([text_set,\n",
    "                       AOI_setting,\n",
    "                       one_hot_columns,\n",
    "                       ml,\n",
    "                       np.mean(a), st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))])\n",
    "df_results = pd.DataFrame(for_df)\n",
    "df_results.columns = [\"text_set\",\"AOI_Setting\",\"Feature set\",\"ml\",\"mean_acc\",\"ci\"]\n",
    "results_filename = \"./results_test.csv\"\n",
    "df_results.to_csv(results_filename, index=None)\n",
    "            #break\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI_setting_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6\n",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
